{
    "contents" : "#' take out the substring of the url of \"https://www.facebook.com/123456789/posts/12345678\"\n#' @param str the complete string of url\n#' @export\n#' @return the substring of url\n#' @keywords string substring\n\n\ndrop = function(str){\n  sstr = substr(str, start = 25, stop = nchar(str))\n  return(sstr)  \n}\n\n#' create adjacency matrix\n#' @param x the subjects to construct rows \n#' @param y the subjects to construct columns\n#' @export\n#' @return the adjacency matrix of x and y\n#' @keywords adjacency matrix \n\ncreateA <- function(x,y)\n{\n  ux = unique(x); uy = unique(y);\n  n  = length(x); nx = length(ux); ny = length(uy)\n  cx = match(x,ux); cy = match(y,uy);\n  A  = spMatrix(nrow = nx , ncol = ny, \n                i = cx , j = cy , x = rep(1,n))\n  \n  #up = lapply(uy,drop2)\n  up=uy\n  colnames(A) = up\n  \n  rownames(A) = ux\n  \n  return(A)\n}\n\n#' create the matrix of all users by words\n#' users are the row subjects\n#' words are the words post by users\n#' @param A adjacency matrix of users by posts\n#' @export\n#' @return the matrix of all users by words\n#' @keywords adjacency matrix \n\n\ncreate_fanwords <- function(A)\n{\n  fan = A %>% rownames %>% unique\n  cfan = match(A %>% rownames,fan)\n  nx=length(fan);ny=length(A[1,])\n  \n  B = spMatrix(nrow = nx , ncol = ny, \n               i = cfan[A@i+1]  , j = A@j+1 , x = A@x ) \n  rownames(B) = fan\n  colnames(B) = colnames(A)\n  return(B)\n}\n\n#' combine two sparse matrix\n#' @param A1 sparse matrix 1\n#' @param A2 sparse matrix 2\n#' @export\n#' @return the large matrix which is the combination of A1 and A2\n#' @keywords combine sparse matrix\n\n\ncombind_fanwords <- function(A1,A2)\n{\n  rn1 = A1 %>% rownames; rn2 = A2 %>% rownames\n  cn1 = A1 %>% colnames; cn2 = A2 %>% colnames\n  \n  fan = c(rn1, rn2) %>% unique\n  cfan1 = match(rn1,fan)\n  cfan2 = match(rn2,fan)\n  \n  words = c(cn1, cn2) %>% unique\n  cword1 = match(cn1,words)\n  cword2 = match(cn2,words)\n  \n  nx=length(fan);ny=length(words)\n  \n  Bi = NULL; Bj = NULL; Bx = NULL;\n  for (i in 1:nx)\n  {\n    cf = which(cfan1==i);     \n    ci = which(A1@i %in% (cf-1)); uj = cword1[(A1@j[ci]+1)]; ni = length(ci);\n    Bi = c(Bi,rep(i,ni)); Bj = c(Bj, uj); Bx = c(Bx,A1@x[ci])\n    \n    cf = which(cfan2==i);    \n    ci = which(A2@i %in% (cf-1)); uj = cword2[(A2@j[ci]+1)]; ni = length(ci);\n    Bi = c(Bi,rep(i,ni)); Bj = c(Bj, uj); Bx = c(Bx,A2@x[ci])\n  }\n  \n  B = spMatrix(nrow = nx , ncol = ny, \n               i = Bi  , j = Bj , x = Bx )  \n  \n  colnames(B)=words\n  rownames(B)=fan\n  return(B)\n}\n\n#' Do SVD to matrix with normalization\n#' @param A adjacency matrix\n#' @export\n#' @return top 20 singular values and singular vectors\n#' @keywords SVD normalization\n\nsvdmatrix <- function(A)\n{\n  rs=rowSums(A);cs=colSums(A)\n  L = Diagonal(length(rs),1/sqrt(rs + mean(rs)))%*%\n    A%*%Diagonal(length(cs),1/sqrt(cs + mean(cs)))\n  sf=irlba(L,nu=20,nv=20)\n  return(sf)\n}\n\n#' do svd sorted by time\n#' @param v data to do SVD\n#' @param datem time of data\n#' @param cc membership vector of data (which post belongs to which candidate)\n#' @param npost number of posts\n#' @param ncluster number of clusters\n\nsv_bydate <- function(v , datem, cc, npost, ncluster)\n{\n  id=1:npost\n  dfvd=data.frame(v,datem,cc,id)\n  dfvdo=dfvd[order(dfvd$cc,dfvd$datem),]\n  dfvdo=as.matrix(dfvdo)\n  vd=dfvdo[,1:ncluster]\n  \n  dfvdl=dfvd[order(dfvd$datem),]\n  dfvdl=as.matrix(dfvdl)\n  vdl=dfvdl[,1:ncluster]\n  \n  datem_od=dfvdl[,(ncluster+1)]\n  daten=rep(1,ndate)\n  for(i in 2:ndate){daten[i]=sum(datem_od<=(i-1))+1}\n  return(list(vd=vd,vdl=vdl,dfvdl=dfvdl,daten=daten))\n}\n\n#' clean text\n#' remove stopwords\n#' remove numbers\n#' @param x original text\n#' @export\n#' @return TermDocumentMatrix after cleaning\n#' @keywords text clean TermDocumentMatrix\n\ntextclean <- function (x)\n{\n  myStopwords <- c(stopwords(\"French\"),\n                   \"http\",\"www\",\"facebook\",\"com\",\"le\")\n  myCorpus <- x %>% VectorSource %>% Corpus\n  myCorpus <- myCorpus %>% tm_map(removeWords,myStopwords) %>% tm_map(removeNumbers)\n  mytdm <- myCorpus %>% TermDocumentMatrix\n  return(mytdm)\n}\n\n#' find frequent words in TermDocumenMatrix\n#' @param mytdm the TermDocumentMatrix\n#' @param rname rownames of the matrix\n#' @export \n#' @return matrix of word frequency\n\nfreqmatr <- function(mytdm,rname)\n{\n  \n  freqterm <- findFreqTerms(mytdm, lowfreq = (length(mytdm$ncol)/1000), highfreq = Inf)\n  \n  textclean <- function(x,rname)\n  {\n    myCorpus <- x %>% VectorSource %>% Corpus\n    myCorpus <- myCorpus %>% tm_map(removeWords,myStopwords) %>% tm_map(removeNumbers)\n    \n    mytdm <- myCorpus %>% TermDocumentMatrix\n    freqterm <- findFreqTerms(mytdm, lowfreq = (length(x)/1000), highfreq = Inf)\n    \n    freqc <- mytdm[freqterm,]\n    freqm <- spMatrix(nrow=freqc$ncol,ncol=freqc$nrow,i=freqc$j,j=freqc$i,x=freqc$v)\n    colnames(freqm) <- freqterm\n    rownames(freqm) <- rname\n    return(freqm)\n  }\n}\n  \n#' draw balloon plot\n#' @param M data\n#' @param logTran do log transformation or not\n#' @param sqrtTran do squareroot transformation or not\n#' @param main name of this balloon plot\n#' @param namesx column names\n#' @param namesy row names\n#' @param margin number of margin of this balloon plot\n#' @param mult number of repetition of this balloon plot\n#' @export\n#' @return a balloon Plot\n\nballoonPlot = function(M, logTran, sqrtTran, main, namesx, namesy, margin, mult){\n  # M is a matrix. want to plot each element as a dot.  \n  # dot size corresponds to magnitude.\n  # dot color black/red corresponds to sign.\n  \n  n = nrow(M)\n  d = ncol(M)\n  \n  scaleItMean = mean(abs(M))\n  \n  if(logTran){\n    scaleItMean = mean(log(abs(M) +1))\n  }\n  if(sqrtTran){\n    scaleItMean = mean(sqrt(abs(M)))\n  }\n  par(mar = c(margin,margin,2,2))\n  plot(c(.5,d+.5), c(.5,n+.5), col = \"white\", main = main, axes = F, ylab = \"\", xlab =\"\")\n  if(length(namesx) !=F)    axis(1, at = 1:d, labels = namesx, lty = 0, las = 2)\n  if(length(namesy) !=F)    axis(2, at = n:1, labels = namesy, lty = 0, las = 2)\n  \n  \n  for(i in 1:n){\n    for(j in 1:d){\n      dotSize = abs(M[i,j])/scaleItMean\n      if(logTran) dotSize = log(dotSize + 1)/scaleItMean\n      if(sqrtTran) dotSize = sqrt(dotSize)/scaleItMean\n      dotColor = \"black\"\n      if(M[i,j] < 0) dotColor = \"red\"\n      points(j,n+1 - i, pch = 19, cex = dotSize*mult, col = dotColor)\n      \n    }\n  }\n}\n\n#' @import dplyr\n#' @import irlba\n#' @import RSQLite\n#' @import Matrix\n",
    "created" : 1430755803737.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3674840367",
    "id" : "83605F32",
    "lastKnownWriteTime" : 1430757353,
    "path" : "C:/Users/Administrator/Frenchpj/SpeClust/R/SpeClust.R",
    "project_path" : "R/SpeClust.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}